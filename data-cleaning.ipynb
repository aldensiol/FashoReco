{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.join(os.getcwd(),\"data\")\n",
    "df_i = pd.read_csv(os.path.join(path, \"articles.csv\"))\n",
    "df_c = pd.read_csv(os.path.join(path, \"customers.csv\"))\n",
    "df_t = pd.read_csv(os.path.join(path, \"transactions_train.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/x7/3z2kdq9n7z53k1nm0tq2fyw00000gn/T/ipykernel_64664/610467727.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cleaned_df_i.fillna('Unknown', inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "article_id                      0\n",
       "prod_name                       0\n",
       "product_type_no                 0\n",
       "product_type_name               0\n",
       "product_group_name              0\n",
       "graphical_appearance_name       0\n",
       "colour_group_name               0\n",
       "perceived_colour_value_name     0\n",
       "perceived_colour_master_name    0\n",
       "index_group_name                0\n",
       "garment_group_name              0\n",
       "detail_desc                     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Cleaning df_i ###\n",
    "\n",
    "# Drop product_code, graphical_appearance_no, colour_group_code, department_no, department_name,\n",
    "# index_name, section_name, perceived_colour_value_id, perceived_colour_master_id, index_code,\n",
    "# index_group_no, section_no, garment_group_no\n",
    "\n",
    "# columns_to_drop_i = ['product_code', 'graphical_appearance_no', 'colour_group_code', 'department_no',\n",
    "#                      'department_name', 'index_name', 'section_name', 'perceived_colour_value_id',\n",
    "#                      'perceived_colour_master_id', 'index_code', 'index_group_no', 'section_no',\n",
    "#                      'garment_group_no']\n",
    "columns_to_keep_i = ['article_id', 'prod_name', 'product_type_no', 'product_type_name', 'product_group_name',\n",
    "                     'graphical_appearance_name', 'colour_group_name', 'perceived_colour_value_name',\n",
    "                     'perceived_colour_master_name', 'index_group_name', 'garment_group_name', 'detail_desc']\n",
    "cleaned_df_i = df_i[columns_to_keep_i]\n",
    "\n",
    "# Replace NaN values in detail_desc with 'Unknown'\n",
    "\n",
    "cleaned_df_i.fillna('Unknown', inplace=True)\n",
    "cleaned_df_i['detail_desc'].isnull().any()\n",
    "\n",
    "# Check cleaning\n",
    "cleaned_df_i.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "customer_id               0\n",
       "age                       0\n",
       "fashion_news_frequency    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Cleaning df_c ###\n",
    "\n",
    "# Drop FN, Active, club_member_status, postal_code\n",
    "\n",
    "columns_to_keep = ['customer_id', 'age', 'fashion_news_frequency']\n",
    "cleaned_df_c = df_c[columns_to_keep]\n",
    "cleaned_df_c = cleaned_df_c.drop_duplicates(subset='customer_id', keep='first')\n",
    "\n",
    "# Replace “None” with “NONE” in fashion_news_frequency\n",
    "# Replace NA values in fashion_news_frequency with “NONE”\n",
    "# Replace NA values in age with mean age\n",
    "\n",
    "new_value = \"NONE\"\n",
    "old_value = 'None'\n",
    "cleaned_df_c['fashion_news_frequency'].replace(old_value, new_value, inplace=True)\n",
    "cleaned_df_c['fashion_news_frequency'].fillna(new_value, inplace=True)\n",
    "\n",
    "mean_age = cleaned_df_c['age'].mean()\n",
    "cleaned_df_c['age'].fillna(mean_age, inplace=True)\n",
    "\n",
    "\n",
    "# Check cleaning\n",
    "cleaned_df_c.head()\n",
    "cleaned_df_c.isnull().sum()\n",
    "#Exporting to package\n",
    "# cleaned_df_i.to_pickle('cleaned_df_i.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t_dat               datetime64[ns]\n",
      "customer_id                 object\n",
      "article_id                   int64\n",
      "price                      float64\n",
      "sales_channel_id             int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "### Cleaning df_t ###\n",
    "cleaned_df_t = df_t\n",
    "\n",
    "# Change t_dat to date type\n",
    "cleaned_df_t['t_dat'] = pd.to_datetime(cleaned_df_t['t_dat'], format=\"%Y-%m-%d\")\n",
    "\n",
    "\n",
    "# Check cleaning\n",
    "print(cleaned_df_t.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_t_train = cleaned_df_t[(cleaned_df_t['t_dat'] >= '2019-04-01') & (cleaned_df_t['t_dat'] <= '2019-06-14')]\n",
    "df_t_val = cleaned_df_t[(cleaned_df_t['t_dat'] >= '2019-06-15') & (cleaned_df_t['t_dat'] <= '2019-06-21')]\n",
    "df_t_test = cleaned_df_t[(cleaned_df_t['t_dat'] >= '2019-06-22') & (cleaned_df_t['t_dat'] <= '2019-06-28')]\n",
    "\n",
    "df_c_train = cleaned_df_c[cleaned_df_c['customer_id'].isin(df_t_train['customer_id'])]\n",
    "df_c_val = cleaned_df_c[cleaned_df_c['customer_id'].isin(df_t_val['customer_id'])]\n",
    "df_c_test = cleaned_df_c[cleaned_df_c['customer_id'].isin(df_t_test['customer_id'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Left join df_t_train with df_c_train on customer_id\n",
    "joined_df_t_c_train = pd.merge(df_t_train, df_c_train, on='customer_id', how='left')\n",
    "\n",
    "# Left join joined_df_t_c_train with cleaned_df_i on articles_id\n",
    "joined_df_t_c_i_train = pd.merge(joined_df_t_c_train, cleaned_df_i, on='article_id', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exporting Cleaned Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_t_train.to_pickle(os.path.join(os.getcwd(),'data','df_t_train.pkl'))\n",
    "df_t_val.to_pickle(os.path.join(os.getcwd(),'data', 'df_t_val.pkl'))\n",
    "df_t_test.to_pickle(os.path.join(os.getcwd(),'data', 'df_t_test.pkl'))\n",
    "df_c_train.to_pickle(os.path.join(os.getcwd(),'data', 'df_c_train.pkl'))\n",
    "df_c_val.to_pickle(os.path.join(os.getcwd(),'data', 'df_c_val.pkl'))\n",
    "df_c_test.to_pickle(os.path.join(os.getcwd(),'data', 'df_c_test.pkl'))\n",
    "cleaned_df_i.to_pickle(os.path.join(os.getcwd(),'data', 'cleaned_df_i.pkl'))\n",
    "joined_df_t_c_i_train.to_pickle(os.path.join(os.getcwd(), 'data', 'joined_df_t_c_i_train.pkl'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "testing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
