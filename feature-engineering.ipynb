{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "# from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.path.join(os.getcwd(), 'data', 'cleaned_data')\n",
    "df_i = pd.read_pickle(os.path.join(data_dir, 'cleaned_df_i.pkl'))\n",
    "df_c_train = pd.read_pickle(os.path.join(data_dir, 'df_c_train.pkl'))\n",
    "df_t_train = pd.read_pickle(os.path.join(data_dir, 'df_t_train.pkl'))\n",
    "df_c_val = pd.read_pickle(os.path.join(data_dir, 'df_c_val.pkl'))\n",
    "df_t_val = pd.read_pickle(os.path.join(data_dir, 'df_t_val.pkl'))\n",
    "df_c_test = pd.read_pickle(os.path.join(data_dir, 'df_c_test.pkl'))\n",
    "df_t_test = pd.read_pickle(os.path.join(data_dir, 'df_t_test.pkl'))\n",
    "joined_df_train = pd.read_pickle(os.path.join(data_dir, 'joined_df_t_c_i_train.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_i['structured_desc'] = df_i[['prod_name', 'product_type_name', 'product_group_name']].apply(lambda x: ' '.join(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_descriptions = df_i['structured_desc'].apply(lambda x: x.split())\n",
    "embedding_dim = 100\n",
    "word2vec_model = Word2Vec(sentences=tokenized_descriptions, vector_size=embedding_dim, window=3, min_count=1, workers=4)\n",
    "\n",
    "def generate_item_embedding(description, model):\n",
    "    word_vectors = [model.wv[word] for word in description if word in model.wv]\n",
    "    if word_vectors:\n",
    "        return np.mean(word_vectors, axis=0)\n",
    "    else:\n",
    "        return np.zeros(embedding_dim)\n",
    "df_i['embedding'] = tokenized_descriptions.apply(lambda x: generate_item_embedding(x, word2vec_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>prod_name</th>\n",
       "      <th>product_type_no</th>\n",
       "      <th>product_type_name</th>\n",
       "      <th>product_group_name</th>\n",
       "      <th>graphical_appearance_name</th>\n",
       "      <th>colour_group_name</th>\n",
       "      <th>perceived_colour_value_name</th>\n",
       "      <th>perceived_colour_master_name</th>\n",
       "      <th>index_group_name</th>\n",
       "      <th>garment_group_name</th>\n",
       "      <th>detail_desc</th>\n",
       "      <th>structured_desc</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>108775015</td>\n",
       "      <td>Strap top</td>\n",
       "      <td>253</td>\n",
       "      <td>Vest top</td>\n",
       "      <td>Garment Upper body</td>\n",
       "      <td>Solid</td>\n",
       "      <td>Black</td>\n",
       "      <td>Dark</td>\n",
       "      <td>Black</td>\n",
       "      <td>Ladieswear</td>\n",
       "      <td>Jersey Basic</td>\n",
       "      <td>Jersey top with narrow shoulder straps.</td>\n",
       "      <td>Strap top Vest top Garment Upper body</td>\n",
       "      <td>[0.16747095, 0.77091706, 0.45015836, 0.7519173...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>108775044</td>\n",
       "      <td>Strap top</td>\n",
       "      <td>253</td>\n",
       "      <td>Vest top</td>\n",
       "      <td>Garment Upper body</td>\n",
       "      <td>Solid</td>\n",
       "      <td>White</td>\n",
       "      <td>Light</td>\n",
       "      <td>White</td>\n",
       "      <td>Ladieswear</td>\n",
       "      <td>Jersey Basic</td>\n",
       "      <td>Jersey top with narrow shoulder straps.</td>\n",
       "      <td>Strap top Vest top Garment Upper body</td>\n",
       "      <td>[0.16747095, 0.77091706, 0.45015836, 0.7519173...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>108775051</td>\n",
       "      <td>Strap top (1)</td>\n",
       "      <td>253</td>\n",
       "      <td>Vest top</td>\n",
       "      <td>Garment Upper body</td>\n",
       "      <td>Stripe</td>\n",
       "      <td>Off White</td>\n",
       "      <td>Dusty Light</td>\n",
       "      <td>White</td>\n",
       "      <td>Ladieswear</td>\n",
       "      <td>Jersey Basic</td>\n",
       "      <td>Jersey top with narrow shoulder straps.</td>\n",
       "      <td>Strap top (1) Vest top Garment Upper body</td>\n",
       "      <td>[0.06088616, 0.8013817, 0.3435098, 0.6323141, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>110065001</td>\n",
       "      <td>OP T-shirt (Idro)</td>\n",
       "      <td>306</td>\n",
       "      <td>Bra</td>\n",
       "      <td>Underwear</td>\n",
       "      <td>Solid</td>\n",
       "      <td>Black</td>\n",
       "      <td>Dark</td>\n",
       "      <td>Black</td>\n",
       "      <td>Ladieswear</td>\n",
       "      <td>Under-, Nightwear</td>\n",
       "      <td>Microfibre T-shirt bra with underwired, moulde...</td>\n",
       "      <td>OP T-shirt (Idro) Bra Underwear</td>\n",
       "      <td>[-0.36702323, -0.26560035, -0.9847349, 0.39013...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>110065002</td>\n",
       "      <td>OP T-shirt (Idro)</td>\n",
       "      <td>306</td>\n",
       "      <td>Bra</td>\n",
       "      <td>Underwear</td>\n",
       "      <td>Solid</td>\n",
       "      <td>White</td>\n",
       "      <td>Light</td>\n",
       "      <td>White</td>\n",
       "      <td>Ladieswear</td>\n",
       "      <td>Under-, Nightwear</td>\n",
       "      <td>Microfibre T-shirt bra with underwired, moulde...</td>\n",
       "      <td>OP T-shirt (Idro) Bra Underwear</td>\n",
       "      <td>[-0.36702323, -0.26560035, -0.9847349, 0.39013...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   article_id          prod_name  product_type_no product_type_name  \\\n",
       "0   108775015          Strap top              253          Vest top   \n",
       "1   108775044          Strap top              253          Vest top   \n",
       "2   108775051      Strap top (1)              253          Vest top   \n",
       "3   110065001  OP T-shirt (Idro)              306               Bra   \n",
       "4   110065002  OP T-shirt (Idro)              306               Bra   \n",
       "\n",
       "   product_group_name graphical_appearance_name colour_group_name  \\\n",
       "0  Garment Upper body                     Solid             Black   \n",
       "1  Garment Upper body                     Solid             White   \n",
       "2  Garment Upper body                    Stripe         Off White   \n",
       "3           Underwear                     Solid             Black   \n",
       "4           Underwear                     Solid             White   \n",
       "\n",
       "  perceived_colour_value_name perceived_colour_master_name index_group_name  \\\n",
       "0                        Dark                        Black       Ladieswear   \n",
       "1                       Light                        White       Ladieswear   \n",
       "2                 Dusty Light                        White       Ladieswear   \n",
       "3                        Dark                        Black       Ladieswear   \n",
       "4                       Light                        White       Ladieswear   \n",
       "\n",
       "  garment_group_name                                        detail_desc  \\\n",
       "0       Jersey Basic            Jersey top with narrow shoulder straps.   \n",
       "1       Jersey Basic            Jersey top with narrow shoulder straps.   \n",
       "2       Jersey Basic            Jersey top with narrow shoulder straps.   \n",
       "3  Under-, Nightwear  Microfibre T-shirt bra with underwired, moulde...   \n",
       "4  Under-, Nightwear  Microfibre T-shirt bra with underwired, moulde...   \n",
       "\n",
       "                             structured_desc  \\\n",
       "0      Strap top Vest top Garment Upper body   \n",
       "1      Strap top Vest top Garment Upper body   \n",
       "2  Strap top (1) Vest top Garment Upper body   \n",
       "3            OP T-shirt (Idro) Bra Underwear   \n",
       "4            OP T-shirt (Idro) Bra Underwear   \n",
       "\n",
       "                                           embedding  \n",
       "0  [0.16747095, 0.77091706, 0.45015836, 0.7519173...  \n",
       "1  [0.16747095, 0.77091706, 0.45015836, 0.7519173...  \n",
       "2  [0.06088616, 0.8013817, 0.3435098, 0.6323141, ...  \n",
       "3  [-0.36702323, -0.26560035, -0.9847349, 0.39013...  \n",
       "4  [-0.36702323, -0.26560035, -0.9847349, 0.39013...  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_i.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spending Power of Customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Training Set\n",
    "df_c_train = pd.merge(df_t_train, df_c_train, on='customer_id')\n",
    "df_c_train = df_c_train.groupby(['customer_id'])['price'].sum().reset_index()\n",
    "df_c_train.rename(columns={'price': 'total_spent'}, inplace=True)\n",
    "\n",
    "# For Validation Set\n",
    "df_c_val = pd.merge(df_t_val, df_c_val, on='customer_id')\n",
    "df_c_val = df_c_val.groupby(['customer_id'])['price'].sum().reset_index()\n",
    "df_c_val.rename(columns={'price': 'total_spent'}, inplace=True)\n",
    "\n",
    "# For Testing Set\n",
    "df_c_test = pd.merge(df_t_test, df_c_test, on='customer_id')\n",
    "df_c_test = df_c_test.groupby(['customer_id'])['price'].sum().reset_index()\n",
    "df_c_test.rename(columns={'price': 'total_spent'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantiles_train = df_c_train['total_spent'].quantile([0, 0.25, 0.75, 1.0])\n",
    "quantiles_val = df_c_val['total_spent'].quantile([0, 0.25, 0.75, 1.0])\n",
    "quantiles_test = df_c_test['total_spent'].quantile([0, 0.25, 0.75, 1.0])\n",
    "\n",
    "def categorize_spending_power(amount, quantiles):\n",
    "    if amount <= quantiles[0.25]:\n",
    "        return 'low'\n",
    "    elif amount <= quantiles[0.75]:\n",
    "        return 'medium'\n",
    "    else:\n",
    "        return 'high'\n",
    "\n",
    "df_c_train['spending_power'] = df_c_train['total_spent'].apply(lambda x: categorize_spending_power(x, quantiles_train))\n",
    "df_c_val['spending_power'] = df_c_val['total_spent'].apply(lambda x: categorize_spending_power(x, quantiles_val))\n",
    "df_c_test['spending_power'] = df_c_test['total_spent'].apply(lambda x: categorize_spending_power(x, quantiles_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spending_power\n",
      "medium    148271\n",
      "low        74241\n",
      "high       74171\n",
      "Name: count, dtype: int64\n",
      "spending_power\n",
      "medium    108324\n",
      "low        54783\n",
      "high       54369\n",
      "Name: count, dtype: int64\n",
      "spending_power\n",
      "medium    234880\n",
      "low       117452\n",
      "high      117441\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_c_test['spending_power'].value_counts())\n",
    "print(df_c_val['spending_power'].value_counts())\n",
    "print(df_c_train['spending_power'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preferred Products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(df_t_train, df_i, on='article_id', how='left')\n",
    "grouped_df = merged_df.groupby(['customer_id', 'product_group_name']).size().reset_index(name='purchase_count')\n",
    "idx = grouped_df.groupby(['customer_id'])['purchase_count'].transform(max) == grouped_df['purchase_count']\n",
    "preferred_products = grouped_df[idx][['customer_id', 'product_group_name']]\n",
    "df_c_train = pd.merge(df_c_train, preferred_products, on='customer_id', how='left')\n",
    "df_c_train.rename(columns={'product_group_name': 'preferred_prod'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(df_t_val, df_i, on='article_id', how='left')\n",
    "grouped_df = merged_df.groupby(['customer_id', 'product_group_name']).size().reset_index(name='purchase_count')\n",
    "idx = grouped_df.groupby(['customer_id'])['purchase_count'].transform(max) == grouped_df['purchase_count']\n",
    "preferred_products = grouped_df[idx][['customer_id', 'product_group_name']]\n",
    "df_c_val = pd.merge(df_c_val, preferred_products, on='customer_id', how='left')\n",
    "df_c_val.rename(columns={'product_group_name': 'preferred_prod'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(df_t_test, df_i, on='article_id', how='left')\n",
    "grouped_df = merged_df.groupby(['customer_id', 'product_group_name']).size().reset_index(name='purchase_count')\n",
    "idx = grouped_df.groupby(['customer_id'])['purchase_count'].transform(max) == grouped_df['purchase_count']\n",
    "preferred_products = grouped_df[idx][['customer_id', 'product_group_name']]\n",
    "df_c_test = pd.merge(df_c_test, preferred_products, on='customer_id', how='left')\n",
    "df_c_test.rename(columns={'product_group_name': 'preferred_prod'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>total_spent</th>\n",
       "      <th>spending_power</th>\n",
       "      <th>preferred_prod</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00000dbacae5abe5e23885899a1fa44253a17956c6d1c3...</td>\n",
       "      <td>0.033864</td>\n",
       "      <td>low</td>\n",
       "      <td>Garment Lower body</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00000dbacae5abe5e23885899a1fa44253a17956c6d1c3...</td>\n",
       "      <td>0.033864</td>\n",
       "      <td>low</td>\n",
       "      <td>Garment Upper body</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000423b00ade91418cceaf3b26c6af3dd342b51fd051e...</td>\n",
       "      <td>0.316729</td>\n",
       "      <td>high</td>\n",
       "      <td>Swimwear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0000b7a134c3ec0d8842fad1fd4ca28517424c14fc4848...</td>\n",
       "      <td>0.059288</td>\n",
       "      <td>medium</td>\n",
       "      <td>Garment Full body</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000d6c053fc8f9389d4565051f12402d5774aa4a9d2e5...</td>\n",
       "      <td>0.089763</td>\n",
       "      <td>medium</td>\n",
       "      <td>Garment Upper body</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         customer_id  total_spent  \\\n",
       "0  00000dbacae5abe5e23885899a1fa44253a17956c6d1c3...     0.033864   \n",
       "1  00000dbacae5abe5e23885899a1fa44253a17956c6d1c3...     0.033864   \n",
       "2  0000423b00ade91418cceaf3b26c6af3dd342b51fd051e...     0.316729   \n",
       "3  0000b7a134c3ec0d8842fad1fd4ca28517424c14fc4848...     0.059288   \n",
       "4  0000d6c053fc8f9389d4565051f12402d5774aa4a9d2e5...     0.089763   \n",
       "\n",
       "  spending_power      preferred_prod  \n",
       "0            low  Garment Lower body  \n",
       "1            low  Garment Upper body  \n",
       "2           high            Swimwear  \n",
       "3         medium   Garment Full body  \n",
       "4         medium  Garment Upper body  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_c_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preferred Color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(df_t_train, df_i, on='article_id', how='left')\n",
    "grouped_df = merged_df.groupby(['customer_id', 'colour_group_name']).size().reset_index(name='purchase_count')\n",
    "idx = grouped_df.groupby(['customer_id'])['purchase_count'].transform(max) == grouped_df['purchase_count']\n",
    "preferred_products = grouped_df[idx][['customer_id', 'colour_group_name']]\n",
    "df_c_train = pd.merge(df_c_train, preferred_products, on='customer_id', how='left')\n",
    "df_c_train.rename(columns={'colour_group_name': 'preferred_color'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(df_t_val, df_i, on='article_id', how='left')\n",
    "grouped_df = merged_df.groupby(['customer_id', 'colour_group_name']).size().reset_index(name='purchase_count')\n",
    "idx = grouped_df.groupby(['customer_id'])['purchase_count'].transform(max) == grouped_df['purchase_count']\n",
    "preferred_products = grouped_df[idx][['customer_id', 'colour_group_name']]\n",
    "df_c_val = pd.merge(df_c_val, preferred_products, on='customer_id', how='left')\n",
    "df_c_val.rename(columns={'colour_group_name': 'preferred_color'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(df_t_test, df_i, on='article_id', how='left')\n",
    "grouped_df = merged_df.groupby(['customer_id', 'colour_group_name']).size().reset_index(name='purchase_count')\n",
    "idx = grouped_df.groupby(['customer_id'])['purchase_count'].transform(max) == grouped_df['purchase_count']\n",
    "preferred_products = grouped_df[idx][['customer_id', 'colour_group_name']]\n",
    "df_c_test = pd.merge(df_c_test, preferred_products, on='customer_id', how='left')\n",
    "df_c_test.rename(columns={'colour_group_name': 'preferred_color'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Average Timelag between Purchase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_t_train.sort_values(by=['customer_id', 't_dat'], inplace=True)\n",
    "df_t_train['time_diff'] = df_t_train.groupby('customer_id')['t_dat'].diff()\n",
    "avg_time_diff = df_t_train.groupby('customer_id')['time_diff'].mean().reset_index()\n",
    "avg_time_diff.rename(columns={'time_diff': 'avg_time_diff_btw_purchase'}, inplace=True)\n",
    "df_c_train = pd.merge(df_c_train, avg_time_diff, on='customer_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_t_val.sort_values(by=['customer_id', 't_dat'], inplace=True)\n",
    "df_t_val['time_diff'] = df_t_val.groupby('customer_id')['t_dat'].diff()\n",
    "avg_time_diff = df_t_val.groupby('customer_id')['time_diff'].mean().reset_index()\n",
    "avg_time_diff.rename(columns={'time_diff': 'avg_time_diff_btw_purchase'}, inplace=True)\n",
    "df_c_val = pd.merge(df_c_val, avg_time_diff, on='customer_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_t_test.sort_values(by=['customer_id', 't_dat'], inplace=True)\n",
    "df_t_test['time_diff'] = df_t_test.groupby('customer_id')['t_dat'].diff()\n",
    "avg_time_diff = df_t_test.groupby('customer_id')['time_diff'].mean().reset_index()\n",
    "avg_time_diff.rename(columns={'time_diff': 'avg_time_diff_btw_purchase'}, inplace=True)\n",
    "df_c_test = pd.merge(df_c_test, avg_time_diff, on='customer_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_t_train.to_pickle(os.path.join(os.getcwd(),'data','df_t_train_fe.pkl'))\n",
    "df_t_val.to_pickle(os.path.join(os.getcwd(),'data', 'df_t_val_fe.pkl'))\n",
    "df_t_test.to_pickle(os.path.join(os.getcwd(),'data', 'df_t_test_fe.pkl'))\n",
    "df_c_train.to_pickle(os.path.join(os.getcwd(),'data', 'df_c_train_fe.pkl'))\n",
    "df_c_val.to_pickle(os.path.join(os.getcwd(),'data', 'df_c_val_fe.pkl'))\n",
    "df_c_test.to_pickle(os.path.join(os.getcwd(),'data', 'df_c_test_fe.pkl'))\n",
    "df_i.to_pickle(os.path.join(os.getcwd(),'data', 'df_i_fe.pkl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Style Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "from string import punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fashion Style Dictionary:\n",
      "{'back': 1690196, 'waist': 1422570, 'top': 1131107, 'front': 1087774, 'jersey': 936588, 'sleeves': 874074, 'pockets': 764195, 'hem': 734945, 'straps': 695055, 'weave': 677069}\n"
     ]
    }
   ],
   "source": [
    "all_tokens = []\n",
    "for description in joined_df_train['detail_desc']:\n",
    "    tokens = word_tokenize(description)\n",
    "    all_tokens.extend(tokens)\n",
    "\n",
    "common_words = set(stopwords.words('english') + list(punctuation) + ['the', 'and', 'is', 'are', 'of', 'in', 'on', 'with', 'for', 'to', 'at', 'from', 'as', 'by', 'or'])\n",
    "\n",
    "filtered_tokens = [word for word in all_tokens if word.lower() not in common_words]\n",
    "\n",
    "word_counts = Counter(filtered_tokens)\n",
    "\n",
    "style_dictionary = dict(word_counts.most_common(10))\n",
    "\n",
    "print(\"Fashion Style Dictionary:\")\n",
    "print(style_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['back', 'waist', 'top', 'front', 'jersey', 'sleeves', 'pockets', 'hem', 'straps', 'weave']\n"
     ]
    }
   ],
   "source": [
    "#convert to list\n",
    "style_list = list(style_dictionary.keys())\n",
    "print(style_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "testing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "metadata": {
   "language_info": {
    "name": "python"
   },
   "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
